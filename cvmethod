# -*- coding: utf-8 -*-
"""
Created on Thu May 16 11:31:14 2019

@author: 171101
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor

from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import mean_absolute_error


def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

class analysis:
    def __init__(self,X,Y):
        self.train_X = X
        self.train_Y = Y
    def tree_model(self,params):
        X = self.train_X
        Y = self.train_Y
        
        loo = LeaveOneOut()
        loo.get_n_splits(X)
        
        param  = pd.DataFrame()
        param_grid = {"max_depth": params[0],
                  "min_samples_split": params[1],
                  "min_samples_leaf":params[2]}
        
        for max_depth_param in range(len(param_grid['max_depth'])):
            for min_samples_split_param in range(len(param_grid['min_samples_split'])):
                for min_samples_leaf_param in range(len(param_grid['min_samples_leaf'])):
                    pred_loo,score = [],[]
                    for train_index, test_index in loo.split(X):
                        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
                        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]
                       
                        #model
                        tree_loo = DecisionTreeRegressor(min_samples_split=param_grid['min_samples_split'][min_samples_split_param], 
                                                      max_depth=param_grid['max_depth'][max_depth_param], 
                                                      min_samples_leaf = param_grid['min_samples_leaf'][min_samples_leaf_param],
                                                      random_state=0)
                        tree_loo.fit(X_train, y_train)
                        score.append(tree_loo.score(X_test,y_test))
                        #evaluate
                        pred = tree_loo.predict(X_test)
                        pred_loo.append(pred[0])
                    
                    MAE = mean_absolute_error(Y,pred_loo)
                    MAPE = mean_absolute_percentage_error(Y,pred_loo)
                    param = param.append(pd.DataFrame(np.array([
                                                                param_grid['min_samples_split'][min_samples_split_param],
                                                                param_grid['max_depth'][max_depth_param],
                                                                param_grid['min_samples_leaf'][min_samples_leaf_param],
                                                                MAE,MAPE]).reshape(1,5)))
        param.columns = ['min_samples_split','max_depth','min_samples_leaf','MAE','MAPE']
        return param
    
    def rf_model(self,params):
        X = self.train_X
        Y = self.train_Y

        loo = LeaveOneOut()
        loo.get_n_splits(X)
        
        param  = pd.DataFrame()
        param_grid = {"max_depth": params[0],
                  "max_features": params[1],
                  "n_estimators":params[2]}
        
        for n_estimators_param in range(len(param_grid['n_estimators'])):
            for max_depth_param in range(len(param_grid['max_depth'])):
                for max_features_param in range(len(param_grid['max_features'])):
                    pred_loo = []
                    score = []
                    for train_index, test_index in loo.split(X):
                        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
                        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]
                       
                        #model
                        rf_loo = RandomForestRegressor(n_estimators=param_grid['n_estimators'][n_estimators_param], 
                                                      max_depth=param_grid['max_depth'][max_depth_param], 
                                                      max_features = param_grid['max_features'][max_features_param],
                                                      random_state=0)
                        rf_loo.fit(X_train, y_train)
                        score.append(rf_loo.score(X_test,y_test))
                        #evaluate
                        pred = rf_loo.predict(X_test)
                        pred_loo.append(pred[0])
                    
                    MAE = mean_absolute_error(Y,pred_loo)
                    MAPE = mean_absolute_percentage_error(Y,pred_loo)
                    param = param.append(pd.DataFrame(np.array([
                                                                param_grid['n_estimators'][n_estimators_param],
                                                                param_grid['max_depth'][max_depth_param],
                                                                param_grid['max_features'][max_features_param],
                                                                MAE,MAPE]).reshape(1,5)))
        
        param.columns = ['n_estimators','max_depth','max_features','MAE','MAPE']
        return param
    
    def reg_model(self):
        X = self.train_X
        Y = self.train_Y
        
        loo = LeaveOneOut()
        loo.get_n_splits(X)
        
        param  = pd.DataFrame()
        pred_loo,y_true = [],[]

        for train_index, test_index in loo.split(X):
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]
           
            #model
            reg = LinearRegression()
            reg.fit(X_train, y_train) 
            #evaluate
            pred = reg.predict(X_test)

            pred_loo.append(pred[0])
            y_true.append(y_test)
        MAE = mean_absolute_error(Y,pred_loo)
        MAPE = mean_absolute_percentage_error(Y,pred_loo)
        param = param.append(pd.DataFrame(np.array([MAE,MAPE]).reshape(1,2)))
        param.columns = ['MAE','MAPE']
        return param
    
    def knn_model(self):
        X = self.train_X
        Y = self.train_Y
        
        loo = LeaveOneOut()
        loo.get_n_splits(X)
        
        param  = pd.DataFrame()
        param_grid = {"n_neighbors": range(1,10)}
        
        pred_loo,y_true = [],[]
        for n_neighbors_param in range(len(param_grid['n_neighbors'])):
            for train_index, test_index in loo.split(X):
                X_train, X_test = X.iloc[train_index], X.iloc[test_index]
                y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]
               
                #model
                knn = KNeighborsRegressor(n_neighbors=n_neighbors_param)
                knn.fit(X_train, y_train) 
                #evaluate
                pred = knn.predict(X_test)
                pred_loo.append(pred[0])
                y_true.append(y_test)
        MAE = mean_absolute_error(Y,pred_loo)
        MAPE = mean_absolute_percentage_error(Y,pred_loo)
        param = param.append(pd.DataFrame(np.array([MAE,MAPE]).reshape(1,2)))
    
        param.columns = ['n_neighbors','MAE','MAPE']
        return param
